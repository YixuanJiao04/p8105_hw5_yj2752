---
title: "P8105_hw5_yj2752"
author: "Yixuan Jiao"
output: github_document
---

```{r}
library(purrr)
library(tidyverse)
set.seed(42)
```


## Problem1
Reading all csv merge them into a single file
```{r message = FALSE}
exp_table <- 
  tibble(id = list.files("./data")) %>%
  mutate(file_dir = str_c("./data/",id)) %>%
  mutate(data = map(file_dir, read_csv)) %>%
  unnest(data)
```
Tidy the table
```{r}
exp_table_tidy <- 
  exp_table %>%
  select(-file_dir) %>%
  mutate(id = str_replace(id,".csv","")) %>%
  separate(id,into = c("group","id"), sep = "_") %>%
  pivot_longer(week_1:week_8,names_to = "week", names_prefix = "week_",values_to = "data") 
```

## Problem2
The data is loaded using `read_csv()`.
```{r}
homicide <- read_csv("./data/homicide-data.csv")
```
The raw data contain the victim's basic information(name,race,age,sex), and location and status of the case. Detail descriptive data is generated by `skimr::skim()` below.
```{r}
skimr::skim(homicide)
```
Adding `city_state` column
```{r}
homicide <- 
  homicide %>%
  mutate(city_state = str_c(city,",",state))
```
Generate the table of number of unsolved cases by cities
```{r}
unsolved <-
  homicide %>%
  filter(disposition != "Closed by arrest") %>%
  group_by(city_state) %>%
  summarise(unsolved = n())
```
Generate the table of number of total cases by cities then bind two tables together.
```{r}
total <-
  homicide %>%
    group_by(city_state) %>%
    summarise(total = n())

cases_prop <- 
  full_join(total,unsolved) %>%
  replace(is.na(.),0)
```
Use `prop.test()` to estimate the proportion of unsolved cases and its confidence interval for Baltimor,MD. Use select to only pull out the estimate and confidence interval
```{r}
baltimore_prop <- prop.test(1825,2827)
broom::tidy(baltimore_prop) %>%
  select(estimate,conf.low,conf.high)
```
Now apply `porp.test()` to every cities in the table, then pull out the estimate and confidence interval by `map2()` and `map()` function, then unnest the tibble and select the desired column.
```{r}
cases_prop <- 
  cases_prop %>%
  mutate(prop_test = map2(.x = unsolved, .y = total, ~prop.test(x = .x, n = .y))) %>%
  mutate(prop_test = map(prop_test,broom::tidy)) %>%
  unnest(prop_test) %>%
  select(city_state,estimate,conf.low,conf.high)
```
Reorder the cities by the value of estimate proportion then generate the point plot with error bar, presenting the estimate proportion of unsolved homicide cases of each state.
```{r}
cases_prop %>%
  mutate(city_state = fct_reorder(city_state,estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

## Problem3
Firstly, write a function for simulate normal distribution and generate test statistics and p-value.
```{r}
norm_sim <- function(mu, n = 30, sd = 5) {
  x <- rnorm(n,mean = mu, sd = sd)
  x %>%
    t.test(mu = mu) %>%
    broom::tidy() %>%
    select(estimate,p.value)
}
```
Iterate 5000 times for $\mu = \{0,1,2,3,4,5,6\}$
```{r}
result_df <-
  expand_grid(
    mu =0:6,
    iteration = 1:5000
  ) %>%
    mutate(sim_result = map(mu,norm_sim)) %>%
    unnest(sim_result) %>% 
    select(-iteration)
```
Use `summarise()` to get what we need for the plot ($\hat{\mu}$ and proportion of null rejection).
```{r}
result_df <-
  result_df %>%
    filter(p.value < 0.05) %>%
    group_by(mu) %>%
    summarise(mu_hat = mean(estimate),
              rej_prop = n()/5000)
```

```{r}
result_df %>%
  ggplot(aes(x = mu,y = rej_prop)) +
  geom_point() +
  geom_smooth(method='lm',formula = y ~ x,se = FALSE)
```

```{r}
result_df %>%
  ggplot(aes(x = mu,y = mu_hat)) +
  geom_point() +
  geom_smooth(method='lm',formula = y ~ x,se = FALSE)
```

